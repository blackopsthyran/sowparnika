# Chatbot Fixes - MAX_TOKENS and JSON Dump Issues

## Problems Fixed

### 1. ❌ Raw JSON Being Displayed
**Issue:** Chatbot was showing raw JSON response like:
```
{"candidates":[{"content":{"role":"model"},"finishReason":"MAX_TOKENS",...}
```

**Root Cause:** When response parsing failed, the code was falling back to `JSON.stringify(chatData).slice(0, 200)`, which dumped raw JSON.

**Fix:** 
- Created robust `extractTextFromGemini()` helper function
- Removed JSON dump fallback
- Now properly extracts text from all response shapes
- Falls back to user-friendly message generation instead of JSON

### 2. ❌ MAX_TOKENS Error
**Issue:** Responses were being cut off mid-sentence with `finishReason: "MAX_TOKENS"`.

**Root Cause:** `maxOutputTokens` was set to only 300, which is too low for complete responses.

**Fix:**
- Increased `maxOutputTokens` from 300 to 800 for chat responses
- Increased extraction `maxOutputTokens` from 200 to 300
- Added warning logs when responses are truncated
- Response still displays even if truncated (uses what was generated)

### 3. ❌ Inefficient Property Data Format
**Issue:** Property listings were taking up too many tokens in the prompt.

**Fix:**
- Optimized property summary format (removed redundant details)
- Limited to 5 properties instead of 10
- Shorter format: `"Title — Type in City for ₹Price, BHK"`
- Simplified system prompt to save tokens

## Changes Made

### `/pages/api/chatbot.ts`

1. **Added `extractTextFromGemini()` helper function:**
   - Handles all response shapes (`content.parts`, `content.text`, `candidate.text`, etc.)
   - Safely extracts text without dumping JSON
   - Returns `null` if extraction fails (triggers fallback)

2. **Increased token limits:**
   - Chat response: `maxOutputTokens: 800` (was 300)
   - Extraction: `maxOutputTokens: 300` (was 200)

3. **Optimized property formatting:**
   - Shorter format: `"Title — Type in City for ₹Price, BHK"`
   - Limited to 5 properties max
   - Removed area size, address, and other details from prompt

4. **Improved error handling:**
   - No more JSON dumps
   - Better logging for debugging
   - Graceful fallback to user-friendly messages

5. **Simplified system prompt:**
   - Removed verbose instructions
   - More concise while maintaining clarity
   - Saves tokens for actual responses

## Expected Behavior Now

### ✅ Clean Responses
- Chatbot replies with natural, conversational text
- No raw JSON or error messages
- Properly formatted property suggestions

### ✅ Complete Responses
- Responses up to 800 tokens (much longer than before)
- No more mid-sentence cutoffs
- If truncated, uses what was generated (with warning log)

### ✅ Better Performance
- Fewer tokens used in prompts
- Faster responses
- More room for actual conversation

## Testing

### Test 1: Basic Query
**Input:** "I'm looking to buy a house"
**Expected:** Natural response mentioning available houses, no JSON

### Test 2: Budget Query
**Input:** "I have a budget of 50 lakhs"
**Expected:** 
- Response mentions properties within budget
- Lists 2-3 relevant properties
- No JSON dump
- Complete response (not truncated)

### Test 3: Complex Query
**Input:** "I need a 3 BHK house in Kochi under 1 crore"
**Expected:**
- Extracts: propertyType=House, bhk=3, city=Kochi, maxPrice=10000000
- Lists matching properties
- Natural conversational response
- No errors or JSON

## Debugging

### Check Server Logs
Look for:
- `[Chatbot] ✅ Gemini API successful, response length: XXX chars`
- `[Chatbot] ⚠️ Response was truncated (MAX_TOKENS)` (if occurs)
- `[Chatbot] ❌ Could not extract text` (shouldn't happen now)

### Check Browser Console
Look for:
- `✅ Gemini is working! Response generated by Gemini`
- No error messages
- Clean message in chat

### If Issues Persist

1. **Check API Key:**
   - Visit `/api/test-gpt`
   - Should show success with `gemini-2.5-flash`

2. **Check Token Limits:**
   - If responses are still truncated, increase `maxOutputTokens` to 1000+
   - But 800 should be plenty for most responses

3. **Check Response Parsing:**
   - Look at server logs for response structure
   - Should see `response length: XXX chars` in logs

## Summary

✅ **Fixed:** Raw JSON no longer displayed  
✅ **Fixed:** MAX_TOKENS errors resolved (increased limit)  
✅ **Fixed:** Responses are complete and natural  
✅ **Improved:** Better error handling and logging  
✅ **Optimized:** More efficient token usage  

The chatbot should now work smoothly with clean, natural responses!

